import torch
import torch.nn as nn
import torch.optim as optim
import whisper
import mlflow
import os
import time
import re
import librosa
import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score, f1_score
from src.monitoring.metrics import TRANSCRIPTION_TIME, AUDIO_STRESS_LEVEL

# --- FONCTION PRECLEAN ---
def preclean(text: str) -> str:
    """Nettoyage normalisant pour √©viter les erreurs de parsing du moteur NLP."""
    t = text.lower()
    t = re.sub(r"(\d)([a-z])", r"\1 \2", t)
    t = re.sub(r"([a-z])(\d)", r"\1 \2", t)
    t = re.sub(r"([a-z0-9])([.,!?])([a-z0-9])", r"\1\2 \3", t)
    t = re.sub(r"\s+", " ", t).strip()
    return t

# --- ARCHITECTURE DU R√âSEAU DE NEURONES ---
class SimpleAudioNet(nn.Module):
    def __init__(self, input_dim, num_classes):
        super(SimpleAudioNet, self).__init__()
        self.fc1 = nn.Linear(input_dim, 64)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.2)
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, num_classes)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        return x

# --- CLASSE PRINCIPALE DU MOD√àLE ---
class InterviewModel:
    def __init__(self, model_path="storage/models/emotion_net.pth"):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"Chargement de Whisper sur {self.device}...")
        self.transcriber = whisper.load_model("base", device=self.device)
        
        # Configuration Binaire : 2 classes (Calme = 0, Stress√© = 1)
        self.classifier = SimpleAudioNet(input_dim=5, num_classes=2).to(self.device)
        self.classifier.eval()
        
        if os.path.exists(model_path):
            try:
                self.classifier.load_state_dict(torch.load(model_path, map_location=self.device))
                print("‚úÖ Mod√®le d'√©motion personnalis√© (2 classes) charg√©.")
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur : {e}. Architecture incompatible ou fichier corrompu.")
        else:
            print("‚ÑπÔ∏è Aucun mod√®le d'√©motion trouv√©, utilisation des poids par d√©faut.")

    def transcribe_audio(self, audio_path):
        """Transcription via Whisper avec Prompt Engineering pour les tics."""
        start_time = time.time()
        audio, sr = librosa.load(audio_path, sr=16000)
        audio_duration_s = len(audio) / sr

        # Prompt pour forcer Whisper √† transcrire les h√©sitations sans les censurer
        tic_prompt = "C'est un entretien d'embauche. Le candidat h√©site souvent, il dit euh, bah, voil√†, du coup."

        res = self.transcriber.transcribe(
            audio, 
            fp16=False, 
            language="fr", 
            initial_prompt=tic_prompt
        )
        
        cleaned_text = preclean(res["text"])
        
        elapsed_s = time.time() - start_time
        TRANSCRIPTION_TIME.observe(elapsed_s)
        
        return cleaned_text

    def predict_emotion(self, features):
        """Inf√©rence PyTorch pour la classification d'√©motion."""
        self.classifier.eval()
        input_tensor = torch.tensor(features, dtype=torch.float32).unsqueeze(0).to(self.device)
        
        with torch.no_grad():
            outputs = self.classifier(input_tensor)
            probabilities = torch.softmax(outputs, dim=1)
            predicted_class = torch.argmax(probabilities, dim=1).item()
            confidence = probabilities[0][predicted_class].item()
        
        classes = {0: "Calme", 1: "Stress√©"}
        result_label = classes.get(predicted_class, "Inconnu")
        
        # Monitoring MLflow et Prometheus
        try:
            mlflow.log_metric("emotion_confidence", confidence)
        except: pass
            
        stress_val = 1.0 if result_label == "Stress√©" else 0.0
        AUDIO_STRESS_LEVEL.set(stress_val)
        
        return {"emotion": result_label, "confidence": round(confidence, 4)}

    def train_custom_model(self, df, epochs=50, batch_size=16):
        """Entra√Ænement MLOps avec calcul d'Accuracy et F1-Score."""
        print("üöÄ D√©but de l'entra√Ænement du mod√®le d'√©motion (Architecture Binaire)...")
        self.classifier.train() 
        
        X, y = [], []
        
        # 1. Pr√©paration des donn√©es (Lecture directe du vecteur complet depuis le CSV)
        for _, row in df.iterrows():
            X.append([
                row['volume'], 
                row['zcr'], 
                row['spectral_centroid'], 
                row['tempo'] / 200.0, 
                row['pause_ratio']
            ])
            y.append(int(row['label']))
            
        X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)
        y_tensor = torch.tensor(y, dtype=torch.long).to(self.device)
        
        dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)
        dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)
        
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.classifier.parameters(), lr=0.001)
        
        mlflow.set_tracking_uri(os.getenv("MLFLOW_TRACKING_URI", "http://mlflow:5000"))
        mlflow.set_experiment("Emotion_Audio_DL")
        
        with mlflow.start_run():
            # Boucle d'entra√Ænement
            for epoch in range(epochs):
                total_loss = 0
                for batch_x, batch_y in dataloader:
                    optimizer.zero_grad()
                    outputs = self.classifier(batch_x)
                    loss = criterion(outputs, batch_y)
                    loss.backward()
                    optimizer.step()
                    total_loss += loss.item()
            
            # Phase d'√©valuation pour MLflow
            self.classifier.eval()
            with torch.no_grad():
                outputs = self.classifier(X_tensor)
                _, predicted = torch.max(outputs.data, 1)
                all_preds = predicted.cpu().numpy()
                all_labels = y_tensor.cpu().numpy()
                
            accuracy = accuracy_score(all_labels, all_preds)
            f1 = f1_score(all_labels, all_preds, average='weighted')
            
            # Sauvegarde et Logging
            model_path = "storage/models/emotion_net.pth"
            os.makedirs(os.path.dirname(model_path), exist_ok=True)
            torch.save(self.classifier.state_dict(), model_path)
            
            mlflow.log_param("epochs", epochs)
            mlflow.log_param("batch_size", batch_size)
            mlflow.log_metric("final_loss", total_loss/len(dataloader))
            mlflow.log_metric("accuracy", accuracy)
            mlflow.log_metric("f1_score", f1)
            
            print(f"‚úÖ Entra√Ænement termin√©. Accuracy: {accuracy:.2f}, F1: {f1:.2f}")
            
            return {
                "status": "success", 
                "loss": round(total_loss/len(dataloader), 4),
                "accuracy": round(accuracy, 4),
                "f1_score": round(f1, 4)
            }